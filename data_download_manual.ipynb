{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get CIFAR-10 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In directory ~/data/wcl-data: \n",
    "- wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "- tar -xvf cifar-10-python.tar.gz\n",
    "\n",
    "Follow unzipping instructions: [https://www.cs.toronto.edu/~kriz/cifar.html]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sshad/data/wcl-data/cifar-10-batches-py'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir('/home/sshad/data/wcl-data/cifar-10-batches-py')\n",
    "os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_batch_4',\n",
       " 'readme.html',\n",
       " 'test_batch',\n",
       " 'data_batch_3',\n",
       " 'data_batch_2',\n",
       " 'data_batch_1',\n",
       " 'data_batch_5',\n",
       " 'batches.meta']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_batch_4',\n",
       " 'test_batch',\n",
       " 'data_batch_3',\n",
       " 'data_batch_2',\n",
       " 'data_batch_1',\n",
       " 'data_batch_5']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches =[file for file in os.listdir() if '_batch' in file]\n",
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = batches[2:]\n",
    "val = batches[0] # batch4 is validation set\n",
    "test = batches[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpickling 1 data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickling a batch results in a dictionary\n",
    "batch1 = unpickle('data_batch_1')\n",
    "type(batch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary keys\n",
    "batch1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'batch_label' <class 'bytes'>\n",
      "b'labels' <class 'list'>\n",
      "b'data' <class 'numpy.ndarray'>\n",
      "b'filenames' <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# What are the values?\n",
    "for key in batch1.keys():\n",
    "    print(key, type(batch1[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data** -- a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n",
    "\n",
    "**labels** -- a list of 10000 numbers in the range 0-9. The number at index i indicates the label of the ith image in the array data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Label:  b'training batch 1 of 5'\n",
      "Labels (examples, shape):  [6, 9, 9] 10000\n",
      "Data (shape):  (10000, 3072)\n",
      "Filenames (examples, shape):  [b'leptodactylus_pentadactylus_s_000004.png', b'camion_s_000148.png', b'tipper_truck_s_001250.png'] 10000\n"
     ]
    }
   ],
   "source": [
    "# Look inside: \n",
    "\n",
    "print(\"Batch Label: \", batch1[b'batch_label'])\n",
    "print(\"Labels (examples, shape): \", batch1[b'labels'][:3], len(batch1[b'labels']))\n",
    "print(\"Data (shape): \", batch1[b'data'].shape)\n",
    "print(\"Filenames (examples, shape): \", batch1[b'filenames'][:3], len(batch1[b'filenames']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains another file, called batches.meta. It too contains a Python dictionary object. It has the following entries:\n",
    "\n",
    "**label_names** -- a 10-element list which gives meaningful names to the numeric labels in the labels array described above. \n",
    "\n",
    "For example, `label_names[0] == \"airplane\", label_names[1] == \"automobile\",` etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to efficiently load data into dataset? \n",
    "\n",
    "Pickling data loads it into memory. Implementing unpickling inside Dataset class might not be efficient because it will still load each batch (or all batches) into memory. \n",
    "\n",
    "I will load data here, and save it on disk in a way that makes it easy to work with Dataset.\n",
    "\n",
    "Plan: \n",
    "- do not need batch label, filename\n",
    "- need labels(y) & data(x)\n",
    "\n",
    "**Not a great idea** but I saved them as pickle files and will unpickle inside Dataset class. It is no different than unpickling the original stuff inside the Dataset class. That implementation could be useful for recreation later.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from [SimCLR in Pytorch](https://medium.com/the-owl/simclr-in-pytorch-5f290cb11dd7): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 3072), (60000,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = np.array([],dtype=np.uint8).reshape((0,3072))\n",
    "labels = np.array([])\n",
    "for batch in batches:\n",
    "    data_dict = unpickle(batch)\n",
    "    images = np.append(images,data_dict[b'data'],axis=0)\n",
    "    labels = np.append(labels,data_dict[b'labels'])\n",
    "\n",
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_file(obj, file):\n",
    "    with open(file, 'wb') as f:\n",
    "        pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.chdir('/home/sshad/data/wcl-data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file(images, 'images')\n",
    "pickle_file(labels, 'labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just in case I want to split the data into train/val/test, I will do that here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = images[:40000], labels[:40000]\n",
    "val_images, val_labels = images[40000: 50000], labels[40000:50000]\n",
    "test_images, test_labels = images[50000:], labels[50000:]\n",
    "\n",
    "pickle_file(train_images, 'train_images')\n",
    "pickle_file(train_labels, 'train_labels')\n",
    "pickle_file(val_images, 'val_images')\n",
    "pickle_file(val_labels, 'val_labels')\n",
    "pickle_file(test_images, 'test_images')\n",
    "pickle_file(test_labels, 'test_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_images[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "train_images[0].shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
